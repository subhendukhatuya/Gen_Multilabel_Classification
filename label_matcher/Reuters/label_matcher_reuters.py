# -*- coding: utf-8 -*-
"""aiso-testing (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18R_xLvDnDccTr8LzV_VRJt0LeqHeJHq-
"""

from sentence_transformers import SentenceTransformer, util
import numpy as np
import pandas as pd

# Load the pre-trained model

model = SentenceTransformer('all-MiniLM-L6-v2')
# Your 'questions' dictionary


questions = {
    'acq': 'News related to company acquisitions and mergers.',
    'alum': 'News related to aluminum and the aluminum industry.',
    'barley': 'News related to barley, a cereal grain used in various applications.',
    'bop': 'Balance of payments news, typically covering a country\'s international trade and financial transactions.',
    'carcass': 'News related to animal carcasses, often related to the meat industry.',
    'castor-oil': 'News related to castor oil, which is derived from the castor bean plant.',
    'cocoa': 'News related to cocoa, often associated with the cocoa bean and chocolate production.',
    'coconut': 'News related to coconuts, their cultivation, and various uses.',
    'coconut-oil': 'News related to coconut oil, an edible oil derived from coconuts.',
    'coffee': 'News related to coffee and the coffee industry.',
    'copper': 'News related to copper and the copper mining industry.',
    'copra-cake': 'News related to copra cake, a byproduct of coconut processing.',
    'corn': 'News related to corn (maize), a widely grown cereal grain.',
    'cotton': 'News related to cotton and the cotton industry.',
    'cotton-oil': 'News related to cottonseed oil, an edible oil derived from cottonseeds.',
    'cpi': 'Consumer Price Index (CPI) news, often related to inflation and price changes.',
    'cpu': 'Central Processing Unit (CPU) news, typically related to computer hardware.',
    'crude': 'News related to crude oil, often associated with the oil industry.',
    'dfl': 'News related to the Deutsche Mark (DM), the former currency of Germany.',
    'dlr': 'News related to the U.S. dollar, often covering currency exchange rates.',
    'dmk': 'News related to the Deutsche Mark (DM), the former currency of Germany.',
    'earn': 'News related to earnings and financial performance of companies.',
    'fuel': 'News related to various fuels, such as gasoline, diesel, and others.',
    'gas': 'News related to natural gas and the natural gas industry.',
    'gnp': 'Gross National Product (GNP) news, often related to a country\'s economic output.',
    'gold': 'News related to gold, often associated with the precious metal market.',
    'grain': 'News related to grains in general, which can include wheat, corn, barley, etc.',
    'groundnut': 'News related to groundnuts (peanuts) and their cultivation.',
    'groundnut-oil': 'News related to groundnut oil, an edible oil derived from peanuts.',
    'heat': 'News related to heat or energy sources.',
    'hog': 'News related to hogs (pigs) and the pork industry.',
    'housing': 'News related to the housing market and real estate.',
    'income': 'News related to income levels and distribution.',
    'instal-debt': 'News related to installment debt or financial obligations.',
    'interest': 'News related to interest rates and financial interest.',
    'ipi': 'Industrial Production Index (IPI) news, often related to manufacturing output.',
    'iron-steel': 'News related to iron and steel production and industry.',
    'jet': 'News related to jet aviation and the airline industry.',
    'jobs': 'News related to employment and job market trends.',
    'l-cattle': 'News related to live cattle and the cattle industry.',
    'lead': 'News related to lead, often associated with the lead metal industry.',
    'lei': 'Leading Economic Indicator (LEI) news, often used to predict future economic trends.',
    'lin-oil': 'News related to linseed oil, an edible oil derived from flaxseeds.',
    'livestock': 'News related to livestock farming and related industries.',
    'lumber': 'News related to lumber and the wood industry.',
    'meal-feed': 'News related to animal feed and meal production.',
    'money-fx': 'News related to foreign exchange (forex) and currency markets.',
    'money-supply': 'News related to the money supply and monetary policy.',
    'naphtha': 'News related to naphtha, a hydrocarbon mixture often used as a solvent.',
    'nat-gas': 'News related to natural gas and the natural gas industry.',
    'nickel': 'News related to nickel and the nickel industry.',
    'nkr': 'News related to the Norwegian Krone (NKR), the currency of Norway.',
    'nzdlr': 'News related to the New Zealand Dollar (NZD), the currency of New Zealand.',
    'oat': 'News related to oats, a cereal grain commonly used as food and animal feed.',
    'oilseed': 'News related to oilseeds, which can include various types of seeds used for oil production.',
    'orange': 'News related to oranges and the citrus fruit industry.',
    'palladium': 'News related to palladium, a precious metal often used in industry.',
    'palm-oil': 'News related to palm oil, an edible oil derived from palm fruit.',
    'palmkernel': 'News related to palm kernel oil, an edible oil derived from palm kernels.',
    'pet-chem': 'News related to the petrochemical industry.',
    'platinum': 'News related to platinum, a precious metal often used in industry and jewelry.',
    'potato': 'News related to potatoes and their cultivation.',
    'propane': 'News related to propane, a type of liquefied petroleum gas (LPG).',
    'rand': 'News related to the South African Rand (ZAR), the currency of South Africa.',
    'rape-oil': 'News related to rapeseed oil, an edible oil derived from rapeseeds.',
    'rapeseed': 'News related to rapeseed, a plant whose seeds are used for oil production and animal feed.',
    'reserves': 'News related to reserves, often referring to financial or foreign exchange reserves.',
    'retail': 'News related to the retail industry and retail sales.',
    'rice': 'News related to rice, a staple food grain in many parts of the world.',
    'rubber': 'News related to rubber and the rubber industry.',
    'rye': 'News related to rye, a cereal grain used in various applications.',
    'ship': 'News related to shipping and the maritime industry.',
    'silver': 'News related to silver, often associated with the precious metal market.',
    'sorghum': 'News related to sorghum, a cereal grain used for food and animal feed.',
    'soy-meal': 'News related to soybean meal, a byproduct of soybean processing.',
    'soy-oil': 'News related to soybean oil, an edible oil derived from soybeans.',
    'soybean': 'News related to soybeans, a widely cultivated legume.',
    'strategic-metal': 'News related to strategic metals, which are critical for various industries.',
    'sugar': 'News related to sugar and the sugar industry.',
    'sun-meal': 'News related to sunflower meal, a byproduct of sunflower seed processing.',
    'sun-oil': 'News related to sunflower oil, an edible oil derived from sunflower seeds.',
    'sunseed': 'News related to sunflower seeds and their cultivation.',
    'tea': 'News related to tea and the tea industry.',
    'tin': 'News related to tin and the tin industry.',
    'trade': 'News related to international trade and trade agreements.',
    'veg-oil': 'News related to vegetable oils, often used for cooking and industrial purposes.',
    'wheat': 'News related to wheat, a major cereal grain used for various purposes.',
    'wpi': 'Wholesale Price Index (WPI) news, often related to changes in wholesale prices.',
    'yen': 'News related to the Japanese Yen (JPY), the currency of Japan.',
    'zinc': 'News related to zinc and the zinc industry.'
}








# Generate sentence embeddings for the values in the 'questions' dictionary
question_embeddings = {key: model.encode(value, convert_to_tensor=True, show_progress_bar=False) for key, value in questions.items()}

# Initialize a dictionary to store the top matching labels for each sentence
top_matching_labels = {}

list_labels = []
k = 0
# Read sentences from a text file (replace 'your_text_file.txt' with the actual file path)
with open('./lora_flan_large_prediction_reuters.txt', 'r') as file:
    current_label = None
    for line in file:
        k = k + 1;
        if(k % 1000 == 0):
            print(f"{k}th iteration")
        line = line.strip()
        temp_list = []
        # Check if "Pred:" appears in the line
        if "Pred:" in line:
            # Split the line at "Pred:" and take the part after it
            current_text = line.split("Pred:", 1)[1].strip()

            # Set the current label
            current_label = current_text
            # Split the line into sentences using full stops (periods) as separators
            sentences = current_label.split('.')
            sentences = [sentence.strip() for sentence in sentences if sentence.strip()]
            #print(sentences)

            # Find the top matching key for each sentence
            for i, sentence in enumerate(sentences):
                #print('sentence', sentence)
                words = sentence.split()

                # Define a set of articles and the word 'no'
                articles_and_no = set(['a', 'an', 'the', 'no'])

                words = [element.lower() for element in words]
                if len(set(words)) < 3:
                    #print(words)
                    continue

                # Check if all words in the sentence are in the set of articles and 'no'
                #if all(word.lower() in articles_and_no for word in words):
                #    continue
                #if 'none' not in words and len(words) < 5:
                 #   continue
                similarities = {}
                embedding = model.encode(sentence, convert_to_tensor=True, show_progress_bar=False)
                for key, category_embedding in question_embeddings.items():
                    cos_sim = util.pytorch_cos_sim(embedding, category_embedding)
                    #print('key', cos_sim)
                    similarities[key] = np.mean(cos_sim.cpu().numpy())
                

                #print('Similarities', similarities)
                #x =1/0
                top_matching_key = max(similarities, key=similarities.get)
                #print(top_matching_key)
                temp_list.append(top_matching_key.lower())
        list_labels.append(list(set(temp_list)))
#print(list_labels)
flattened_data = [' '.join(map(str, sublist)) for sublist in list_labels]
#print(flattened_data)
# Convert it to a pandas DataFrame with a single column
df = pd.DataFrame(flattened_data, columns=['Combined_Column'])

# Join the elements within each sublist with space separation
df['Combined_Column'] = df['Combined_Column'].apply(lambda x: ''.join(x))
#df.to_csv('./predicted.csv')
#print(df['Combined_Column'])
#x =1/0


val_aiso = pd.read_csv('test.csv')
val_aiso['Predicted'] = df['Combined_Column']
val_aiso.to_csv('predicted_test_reuters_flan_t5_large_t5xxl.csv')


from sklearn.metrics import f1_score, jaccard_score
from sklearn.preprocessing import MultiLabelBinarizer
ground_truth_labels = val_aiso['labels'].str.split()  # Assuming labels are separated by spaces
predicted_labels = val_aiso['Predicted'].str.split()        # Assuming labels are separated by spaces

#print(predicted_labels) #Initialize the MultiLabelBinarizer to convert labels into binary format
mlb = MultiLabelBinarizer()


# Transform the ground truth and predicted labels into binary format
ground_truth_binary = mlb.fit_transform(ground_truth_labels)
predicted_binary = mlb.transform(predicted_labels)

#print('gt labels', ground_truth_labels)
#print('pred labels', predicted_labels)
#print('gt binary',ground_truth_binary)

#print('pred binary', predicted_binary)

# Calculate the F1 macro score
f1_macro = f1_score(ground_truth_binary, predicted_binary, average='macro')

f1_micro = f1_score(ground_truth_binary, predicted_binary, average='micro')

# Print the F1 macro score
print("F1 Macro Score:", f1_macro)

print("F1 Micro Score:", f1_micro)


from sklearn.metrics import accuracy_score
accuracy_score = accuracy_score(ground_truth_binary, predicted_binary)
print('accuracy score', accuracy_score)

weight = f1_score(ground_truth_binary, predicted_binary, average="weighted", zero_division=0)
jacc = jaccard_score(ground_truth_binary, predicted_binary, average="samples", zero_division=0)

print('weighted', weight, 'jacc', jacc)
